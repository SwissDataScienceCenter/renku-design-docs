- Start Date: 2023-01-20
- Status: Proposed

# Add ssh support to sessions

## Summary

> One paragraph explanation of the change.

An important requirement which must be met by Renku is to enable users to
log in to their Renku session via ssh; a key driver for this is to support
working with VS Code within Renku sessions.

This has been discussed within the team and work is ongoing on an interim
solution which meets the basic requirements. This RFC provides the context,
supports discussion of possible solutions and will be used to document the
final agreed solution.

Note that this RFC must take into account the interim solution used to provide
ssh access as well as any experience gained including (a) user experience with
the current solution, (b) experience developing this solution and (c) experience
operating and managing this solution.

## Motivation

> Why are we doing this? What use cases does it support? What is the expected
outcome?

There is a [Shape-up
document](https://www.notion.so/Support-RenkuLab-compute-access-from-local-terminal-SSH-VSCode-f896d3b391c94bcc87c56e375eb531d6)
which provides the motivation for introducing this functionality.

## Problem Definition

> This section should include a detailed description of the problem and, importantly,
include any specific constraints that arise. It can be as technical as required.

The basic problem is to provide low friction, secure access to user sessions
via ssh. 

From a user perspective, the following needs to be considered:
- key setup
  - user may want to use an existing keypair which is stored in `$HOME/.ssh` on
    their local machine
  - user may have existing keypairs but wants to have a new keypair for this
    scenario
    - having this generated by renku is probably the best option but the user
      may want to be able to control the naming of the file on the local
      machine
  - user may have a password protected key which is accessible via the `ssh-agent`
    - this may require `ForwardAgent` to be configured on the client side
  - user's key may already be in use within gitlab/github
- host key verification
  - if user attempts to log into the server with ssh and it is not a recognized
    server, the user should add the server to the known host keys
    - we should not have too much friction in this process; ie if new host keys
      are generated for each user session, the user will be asked each time to
      confirm that the host key is valid
  - for vscode host key verification is less intrusive
- interaction modes
  - primary use case is one in which the user connects via VS Code; this uses
    `ssh` based tunneling mechanisms to support diverse interactions with the
    remote server including access to remote files, a remote terminal and
    interaction with eg a Jupyter Notebook
  - user should obtain a sensible shell configuration when a terminal is
    created; for ssh-agent forwarding, this likely involves ensuring that the
    `SSH_AUTH_SOCK` is configured
  - user should be able to log into the session with a simple `ssh` command
    - a standard `ssh <username>@<session>` should enable the user to log in

From a system perspective, the following needs to be considered:
- Unlike HTTP/S, ssh does not have support for server identification and hence
  it is not trivial to perform aggregation (or disaggregation) of ssh sessions,
  ie, it is not so straightforward to have a single ssh server to which users
  connect and it will proxy/redirect ssh sessions to the appropriate renku user
  sessions; further, as this carries non-negligible security risks in general,
  this approach is not widely used and there are few off the shelf software
  components designed around such an architecture
- The Renku platform should never see user private keys
- A solution which does not have many moving parts is definitely preferred
  (e.g. we should avoid publishing DNS entries dynamically if possible)
- Solutions which consume large amounts of IP addresses should be avoided as
  they can be costly
- A solution which supports convenient monitoring using the existing Renku
  monitoring approaches is desirable

We consider the following different user scenarios:
- Scenario 1: User is comfortable using ssh keys - bring you own key
  - User imports ssh key to Renku as is common with cloud services
- Scenario 2: User is used to using ssh keys but wants renku to create new key
  - User asks renku to generate key via cli and it gets stored in the .ssh folder
  - User uses this key to log in to renku
- Scenario 3: User is not so familiar with keys; wants renku to generate keys via web interface
  - Private key generated by web UI can be downloaded once and is not
    persisted; user is provided information on what to do with the private key
  - Public key is retained by renku
  - (Will need to be able to deal with the case that user loses key - support
    creation of new key)
  - (Will probably need the command line to perform some check to see if the
    configuration is correct)
- Scenario 4: User is not familiar with terminal interaction at all; wants
  handheld VSCode option
  - It is not clear if VSCode can work with OAuth/OIDC mechanisms in a low
    friction manner

## Key Assumptions

The following key assumptions apply:
- a solution is required which can be deployed both in the cloud provider
  context and in the Switch/Openstack context - assumptions relating to
  ingress configuration and getting access to ssh services must be clear for
  both contexts and map to the design of the different platforms
- we are not targeting the most basic users; we assume they understand the
  need for some security and are willing to put the time/energy required into a
  reasonably sensible ssh configuration
- password authentication to ssh sessions exposed to the Internet is not
  permitted

## Possible solutions

As this work has some kind of history, three solutions have been discussed in
various conversations - those are the first three options below; a fourth
approach arose when presenting these ideas to the team and that is the last
item in the list below:
- an approach in which an ssh port is exposed on each session directly to the
  Internet;
- an approach in which a dedicated jumphost is used and the standard ssh
  proxying mechanisms are used to access the session via the jumphost;
- an approach in which a dedicated proxy is provided as part of the Renku
  platform which provides ssh access without needing to use the ssh client
  proxy capabilities.
- an approach which uses OAuth/OIDC to enable login without using either keys
  or long-term passwords
Each of these approaches is discussed in more detail below.

Other solutions could be envisaged: it could be possible to provide a tunnel
over HTTP/S into the session and access it via ssh locally or perhaps some
wireguard solution might work but these approaches would probably encounter
issues with different OS versions, would not be easy to configure and
ultimately would likely have a detrimental impact on user experience and hence
are not considered further.

### Exposing ssh port from each session directly

In this approach, each user session pod exposes at least 2 ports: an HTTP port
for the Jupyter lab server and an ssh port for the ssh session. These ports
have corresponding services running inside the pod.

Kubernetes services are then linked to these sessions with the ports on the
services mapping to the ports exposed by the pod. An ingress is then mapped to
the ssh services with a dedicated ingress for each ssh session.

Each ingress should have a unique name and also a unique IP address as the ssh
protocol operates on an IP address basis (i.e., it has no specific server
identification as noted above). This solution can suffer from DNS propagation
delays, depending on the DNS provider and DNS configuration. Further, exposing
ssh servers running inside user sessions directly to the Internet brings some
security risks and it would need to be clear that users cannot easily change
the ssh daemon configuration within their sessions to make their session very
exposed.

A couple of further points relating to this approach:
- ingresses on cloud providers can typically be expensive; having one per
  session is likely to incur significant cost;
- on the Switch deployments, the entire cluster is exposed via a single IP
  address; as such it is not straightforward to devise a solution in which
  different sessions would map to different IP addresses.

### Adding a proxy jumphost

Another solution is to have a jumphost and to use this to access the pods. In
this case, a jumphost must be installed inside the kubernetes cluster as it 
requires direct access to the ssh server running on the pods.

This requires modifications to the cluster ingress configuration to forward TCP 
traffic incident on a specific port to the jumphost pod on its ssh port; this
pod must have its sshd configured to support proxying. Also, ssh proxying
approaches require authentication against both the proxy and the destination
server; this necessitates an approach in which some combination of no credentials and
a keypair must be deployed to the proxy and/or user session.

The most natural solution in this case is to use the user's public key within
the session and have open access with no ability to obtain a shell within the
jumphost. Key management then becomes a user responsibility, with user's having
to do this within their renku projects; as such keys are project entities,
rather than user entities.

In this case, the command to ssh into a session requires specifying both the
jumphost and the destination; hence it is a more complex command and introduces
some user friction when accessing sessions. VSCode supports such proxying
scenarios without any problems.

### Using a Man In the Middle (MITM) Proxy solution

The third approach is the one followed by gitpod; in this approach a dedicated
proxy is provided which affords access to the sessions. As with the proxying
approach above, this must run on the kubernetes cluster.

Unlike the above approach, this requires writing and maintaining a software
component. The key difference is that this proxy does not use the proxying
capabilities provided by an ssh client (in which one ssh session is embedded
inside another); effectively this approach concatenates two distinct ssh
sessions with two distinct authentication flows. The proxy terminates one
ssh session and forwards all traffic to another ssh session.

This solution has the following benefits:
- it is possible to log in via a simple ssh command which looks much
  cleaner/more professional;
- there is a single entry point which reduces the attack surface;
- it is reasonably straightforward to add instrumentation such that ssh session
  information data can be easily collected.

The primary downside is that it involves writing and maintaining another
component; however initial work by Tasko indicates that this can be done with
a modest amount of coding effort.

### Using OAuth2/OIDC

After presenting initial ideas above to the team, there were some questions
regarding whether use of OIDC can reduce friction in this process, making
for a smoother user experience. OIDC could obviate the need for keys/passwords
resulting in a simpler user experience.

ssh has support for such mechanisms, providing (a) a means to present
information to the user about how the login process, eg providing a web link
which can be clicked and (b) a mechanism by which another service can be used
to validate login credentials.

OIDC supports two modes which should be considered in this context:
- Authorization Code Flow
- Device Code Flow

The latter is intended for long-lived authentication of a device, such that the
device can act on behalf of the user - Smart TVs are a typical example. In this
approach, a device obtains a token from the authentication service; an authentication
flow takes place *on a different device* which uses this device specific token.
Once that authentication flow completes, the device can act on behalf of the user.
In this case, we don't have a specific, fixed device which should be acting on
behalf of the user; for this reason the Device Code flow is not considered
further.

The Authorization Code Flow is intended for use cases such as this, where some
authentication provider manages user credentials and a token is generated which
can be used to act on behalf of the user outside the browser. In this case, the
token is generated out of band via the web browser or perhaps the renku cli and
this is entered via ssh. The ssh server then validates the generated token.
More specifically, the token can be generated via keycloak and in the
validation process, the ssh server requests keycloak to validate the token
provided.

Use of these mechanisms is not recommended within VSCode.

## Comparison of different approaches

A table showing how the different approaches compare is shown below:

|                                                | Ssh port exposed by session directly | Proxy jumphost    | MITM Proxy         | OAuth2/OIDC       |
|------------------------------------------------|--------------------------------------|-------------------|--------------------|-------------------|
| Efficient IP address usage                   | :x:                                   | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |
| Login controlled by Renku                    | :x:                                   | :x:                | :heavy_check_mark:  | :heavy_check_mark: |
| Keys linked to user rather than project      | :x:                                   | :x:                | :heavy_check_mark:  | :heavy_check_mark: |
| Flexible monitoring support                  | :x:                                   | :x:                | :heavy_check_mark:  | :x:                |
| Key management responsibilities with users   | :x:                                   | :heavy_check_mark: | :heavy_check_mark:  | :x:                |
| Increased complexity of components to manage | :x:                                   | :x:                | :x:                 | :heavy_check_mark: |
| Control over session to ssh name             | :x:                                   | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark: |

## Proposed Solution

The proposed solution is based on the MITM Proxy described above. At an
architectural level, this involves the addition of a component to the Renku
platform which will terminate ssh sessions and route them to the appropriate
user session. It will necessitate a solution for mapping between username, 
keys used for login and the user session.

- Functionalities required:
  - API:
    - CRUD operations on public keys for logged in user
    - Session operations?
  - CLI
    - Push public key for logged in user (check if it is valid public key)
    - Create keypair locally, put key in appropriate folder and push public key
    - Perform some validation of key setup without needing to launch a user session
      - (probably needs to have an endpoint which is always available in the absence of a session) 
    - For OIDC modus:
      - Support generation of token for logged in user
      - Support combined token generation and login via pty?
      - Support login with token generated via web browser
  - UI
    - Import public key for logged in user (check if it is valid public key)
    - Create keypair locally, support download of private key and give user
      instructions on what to do with this
    - For OIDC modus:
      - Support generation of token in browser
  - ssh Proxy
    - Develop new proxy which supports public key login
    - Need to have clarity on the solution for mapping login names to user sessions

## Drawbacks

> Why should we *not* do this? Please consider the impact on users,
on the integration of this change with other existing and planned features etc.

> There are tradeoffs to choosing any path, please attempt to identify them here.

One reason to not do this is that there is currently an interim ssh solution in
place which may be adequate/sufficient; this may become a permanent solution.

## Rationale and Alternatives

> Why is this design the best in the space of possible designs?

> What other designs have been considered and what is the rationale for not choosing them?

> What is the impact of not doing this?

See comparison of approaches above.

## Unresolved questions

> What parts of the design do you expect to resolve through the RFC process before this gets merged?

> What parts of the design do you expect to resolve through the implementation of this feature before stabilisation?

> What related issues do you consider out of scope for this RFC that could be addressed in the future independently of the solution that comes out of this RFC?

